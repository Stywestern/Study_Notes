**Noise (1):**
- **Definition:** Noise refers to unwanted signals that get inserted between the transmitter and receiver, corrupting the intended signal.
- **Thermal Noise:**
    - Caused by the random thermal agitation of electrons in electronic components.
    - It's uniformly distributed across the frequency spectrum, hence the term "white noise."
    - It's unavoidable and present in all electronic systems.
- **Intermodulation Noise:**
    - Occurs when signals at different frequencies share a common medium.
    - Nonlinearities in the medium can cause these signals to mix, generating new signals at frequencies that are the sums and differences of the original frequencies.
    - These new signals interfere with the intended signals.

**Noise (2):**
- **Crosstalk:**
    - Happens when a signal from one transmission line or channel is picked up by another nearby line or channel.
    - This can occur due to electromagnetic coupling between the lines.
- **Impulse Noise:**
    - Consists of irregular pulses or spikes of high amplitude and short duration.
    - Caused by external electromagnetic interference, such as lightning, power line surges, or switching transients.
    - Can cause significant errors in digital data transmission.

![[Pasted image 20250316233122.png]]


**Channel Capacity:**
- **Definition:** The maximum rate at which data can be transmitted over a communication channel under specific conditions.
- **Factors:**
    - **Data Rate:** Measured in bits per second (bps), it's the speed at which data is communicated.
    - **Bandwidth:** Measured in Hertz (Hz), it's the range of frequencies available for transmission. Bandwidth is constrained by the transmitter and the transmission medium.
    - Noise: The amount of noise present on the channel, which limits how reliably data can be transmitted.
- **Importance:**
    - Channel capacity is a fundamental concept in information theory.
    - It determines the theoretical limit on how much information can be transmitted over a channel.
    - The Shannon-Hartley theorem defines the relationship between channel capacity, bandwidth, and signal-to-noise ratio (SNR).

### Shannon Capacity Formula
**1. Context:**
- This formula addresses the fundamental limitations on data transmission in the presence of noise.
- It builds upon the concepts of data rate, noise, and error rate.

**2. Data Rate, Noise, and Error Rate:**
- **Data Rate Impact:**
    - A higher data rate means each bit is transmitted in a shorter time interval.
    - This makes the signal more susceptible to noise bursts, as a single noise burst can corrupt more bits.
    - Therefore, for a given noise level, a higher data rate leads to a higher error rate.
- **Trade-off:**
    - There's a fundamental trade-off between data rate and error rate.
    - To achieve higher data rates, you need to either reduce noise or accept a higher error rate.

**3. Signal-to-Noise Ratio (SNR):**
- **Definition:**
    - SNR is a measure of the power of a signal relative to the power of the background noise.
- **Decibel (dB) Representation:**
    - SNR is often expressed in decibels (dB) using the formula:
        - `SNRdb = 10 log10 (signal/noise)`
    - A higher SNRdb indicates a stronger signal relative to the noise.

**4. Shannon Capacity Formula:**
- **Formula:**
    - `C = B log2(1 + SNR)`
    - Where:
        - `C` is the channel capacity (the maximum theoretical data rate in bits per second).
        - `B` is the bandwidth of the channel in Hertz (Hz).
        - `SNR` is the linear signal-to-noise ratio (not in dB).
- **Interpretation:**
    - This formula gives the theoretical maximum data rate that can be achieved over a noisy channel without errors.
    - It shows that channel capacity is directly proportional to bandwidth and increases with SNR.

**5. Error-Free Capacity:**
- **Theoretical Limit:**
    - The Shannon capacity represents an ideal, error-free limit.
    - In practice, achieving this limit is difficult due to factors like coding inefficiencies and non-ideal channel conditions.
- **Practical Implications:**
    - The formula provides a benchmark for evaluating the performance of communication systems.
    - It guides the design of modulation and coding techniques to approach the theoretical limit.


### Nyquist Bandwidth theorem 

**1. Context:**
- The Nyquist theorem deals with the relationship between bandwidth and the maximum achievable signal rate in a _noiseless_ channel.
- It focuses on how many distinct signal levels can be transmitted within a given bandwidth.

**2. Core Concept:**
- **Signal Rate and Bandwidth:**
    - If the rate of signal transmission is 2B (where B is the bandwidth), then a signal with frequencies no greater than B is sufficient to carry that signal rate.  
    - Conversely, given a bandwidth B, the highest signal rate that can be achieved is 2B.
    
- **Binary Signals:**
    - For a binary signal (using two signal levels, 0 and 1), the data rate supported by a bandwidth B (in Hz) is 2B bits per second (bps).
    - This means that in an ideal noiseless channel, you can transmit twice the bandwidth in bits per second.  

**3. Increasing Data Rate with Multiple Signal Levels (M):**
- **Beyond Binary:**
    - The Nyquist theorem allows for the use of more than two signal levels (M levels) to increase the data rate within a given bandwidth.
    - Each signal level represents a different combination of bits.
- **Formula:**
    - `C = 2B log2(M)`
    - Where:
        - `C` is the channel capacity (maximum data rate in bps).
        - `B` is the bandwidth in Hertz (Hz).
        - `M` is the number of distinct signal levels.
- **Example:**
    - If you have a bandwidth of 1000 Hz and use 4 signal levels (M = 4), the maximum data rate is:
        - `C = 2 * 1000 * log2(4) = 2000 * 2 = 4000 bps`

**4. Data Rate, Bandwidth, and Receiver's Discernment:**
- **Receiver's Role:**
    - The receiver must be able to reliably distinguish between the M different signal levels.
    - The more signal levels used, the closer together they become, making them more susceptible to errors due to noise or distortion.
    - The receiver's ability to discern these levels is crucial for achieving the maximum data rate.
- **Practical Considerations:**
    - In real-world scenarios, noise and channel impairments limit the number of signal levels that can be reliably used.
    - The Nyquist theorem provides a theoretical upper bound, but practical systems may not achieve this limit.  
        

**Examples:**
- **Modems:** Modems use multiple signal levels to increase the data rate over telephone lines.
- **Digital Modulation Techniques:** Techniques like Quadrature Amplitude Modulation (QAM) use multiple amplitude and phase levels to encode more bits per symbol, increasing data rates.  
- **Wireless Communication:** Wireless systems use various modulation schemes with different numbers of signal levels to optimize data rates for the available bandwidth and channel conditions.